# AiTril Configuration Checkpoint - User Preferences

**Last Updated**: 2025-11-29
**Purpose**: Source of truth for AiTril configuration to prevent accidental downgrades or misconfigurations

---

## üö® CRITICAL ARCHITECTURAL DECISION - v0.0.33

**Date**: 2025-11-29
**Status**: PENDING IMPLEMENTATION
**Severity**: CRITICAL - Fundamental design flaw identified

### The Problem: Wrong Models Being Used

**Current v0.0.32 uses GENERAL-PURPOSE models** instead of specialized code/agent models:
- ‚ùå OpenAI: `gpt-4o` (general chat) ‚Üí Should use **Codex** or code-specialized models
- ‚ùå Anthropic: `claude-opus-4-5-20251124` (general API) ‚Üí Should use **Claude Code CLI**
- ‚ùå Gemini: `gemini-2.0-flash-exp` (general) ‚Üí Should use **Gemini ADK** (Agent Development Kit)

### The Fix: v0.0.33 Architecture

**Use specialized code/agent tools instead of general APIs:**

1. **Claude Code CLI Provider** (`ClaudeCodeProvider`)
   - Execute: `claude -p "prompt" --model claude-opus-4-5-20251101`
   - Shell-based invocation of actual Claude Code binary
   - Properly configured for code/agent tasks
   - Environment: `ANTHROPIC_API_KEY` for authentication

2. **OpenAI Codex Integration** (`OpenAICodexProvider`)
   - Use code-specialized models (code-davinci-002, gpt-4-turbo with code focus)
   - Optimize for code generation, analysis, and agent tasks
   - Not general chat completion

3. **Gemini ADK Integration** (`GeminiADKProvider`)
   - Agent Development Kit for specialized agent capabilities
   - Built for agentic workflows, not general chat
   - Tool-use optimized architecture

### Implementation Requirements

**Backward Compatibility**:
- Keep existing API-based providers as fallback (`OpenAIProvider`, `AnthropicProvider`, `GeminiProvider`)
- Add new specialized providers (`ClaudeCodeProvider`, `OpenAICodexProvider`, `GeminiADKProvider`)
- User configuration option to choose API vs. specialized mode

**Provider Hierarchy**:
```
Preferred (v0.0.33+):
  - ClaudeCodeProvider (shell: claude CLI)
  - OpenAICodexProvider (API: Codex models)
  - GeminiADKProvider (ADK: agent-specialized)

Fallback (v0.0.32 compatibility):
  - AnthropicProvider (API: general models)
  - OpenAIProvider (API: general models)
  - GeminiProvider (API: general models)
```

**Configuration Example**:
```bash
# .env additions for v0.0.33
CLAUDE_CODE_CLI_PATH=/usr/local/bin/claude  # Path to Claude Code binary
CLAUDE_CODE_MODEL=claude-opus-4-5-20251101  # Model for Claude Code
USE_SPECIALIZED_PROVIDERS=true              # Enable specialized providers

OPENAI_CODEX_MODEL=code-davinci-002         # Codex model
GEMINI_ADK_ENABLED=true                     # Use ADK instead of API
```

### Why This Matters

**General models** (current):
- Designed for conversation, chat, general knowledge
- Not optimized for code generation, agent behavior
- Missing specialized tooling and context

**Specialized models/tools** (v0.0.33):
- Built specifically for code and agent tasks
- Direct CLI access to properly configured environments
- Tool-use and agentic behavior as first-class features
- Better performance for AiTril's core use cases

### User's Discovery

User realized this when reviewing documentation:
> "we could be doing things like `claude -p "explain this code" --model claude-opus-4-5-20251101` as the command in the backend"

This is **exactly right** - we should invoke specialized tools, not generic API endpoints.

### Action Plan for v0.0.33

1. ‚úÖ Document architectural decision (this checkpoint)
2. ‚è≥ Implement `ClaudeCodeProvider` (shell-based)
3. ‚è≥ Implement `OpenAICodexProvider` (Codex API)
4. ‚è≥ Implement `GeminiADKProvider` (ADK integration)
5. ‚è≥ Add provider selection logic (specialized ‚Üí fallback)
6. ‚è≥ Update configuration files and documentation
7. ‚è≥ Test all providers in isolation
8. ‚è≥ Test tri-lam mode with specialized providers
9. ‚è≥ Publish v0.0.33 to PyPI and DockerHub

**Priority**: HIGH - This fundamentally improves AiTril's capabilities

---

## ‚ö†Ô∏è CRITICAL: Latest 2025 LLM Models

**NOTE**: After v0.0.33, these will be used by SPECIALIZED providers, not general API providers.

**DO NOT DOWNGRADE THESE MODELS!** The user specifically wants the latest 2025 models:

### Primary LLM Providers

| Provider | Model ID | Released | Notes |
|----------|----------|----------|-------|
| OpenAI | `gpt-5.1` | Late 2025 | Latest GPT model |
| Anthropic | `claude-opus-4.5-20251124` | Nov 24, 2025 | Claude Opus 4.5 |
| Google Gemini | `gemini-3-pro-preview` | Nov 18, 2025 | Gemini 3 Pro Preview |
| Ollama | `granite4:350m` | - | Local model |

### Environment Variables (.env)

```bash
# OpenAI Configuration
OPENAI_API_KEY=[set]
OPENAI_MODEL=gpt-5.1

# Anthropic Configuration
ANTHROPIC_API_KEY=[set]
ANTHROPIC_MODEL=claude-opus-4.5-20251124

# Google Gemini Configuration
GOOGLE_API_KEY=AIzaSyBLHOqMtiVbvgH9mp1hILWSXobI6VBeT70
GEMINI_MODEL=gemini-3-pro-preview

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=granite4:350m
```

---

## üéØ Initial Planner Configuration

The user wants an **initial planner agent** that runs first to set groundwork for other agents:

- **Initial Planner**: `openai` (GPT-5.1)
- **Workflow**: Planner creates initial design/plan ‚Üí Other agents improve and build on it
- **Display**: Planner shows first with üìã icon in UI

---

## üåê Web Server Configuration

### Port Settings
- **Port**: `37142` (not 8888 - conflicts with other apps)
- **Reason**: Port 37142 is in registered range (1024-49151) and unlikely to conflict

### Environment Loading
- **Critical**: Web server MUST load `.env` file at startup using `python-dotenv`
- **Location**: `aitril/web.py` lines 24-46
- **Verification**: Check startup logs for "‚úì Loaded environment variables"

---

## üìÅ File Locations

### Configuration Files
```
~/.aitril/settings.json          # User settings (takes precedence)
.env                              # Environment variables (project root)
aitril/settings.py                # Default settings (fallback)
```

### Priority Order
1. `settings.json` model values
2. Environment variables from `.env`
3. Defaults in `settings.py`

**Important**: All three should be kept in sync!

---

## üèóÔ∏è Architecture Preferences

### Provider Support
- **Total Providers**: 8 (OpenAI, Anthropic, Gemini, Ollama, Llama.cpp, Custom1-3)
- **Enabled by Default**: OpenAI, Anthropic, Gemini, Ollama
- **Local Models**: Ollama (enabled), Llama.cpp (disabled)

### UI Features
- ‚öôÔ∏è Settings button MUST be present in sidebar
- üìã Initial planner shows first in agent list
- All enabled providers show in agent panel
- Deployment options after build mode

---

## üö´ Common Mistakes to Avoid

### ‚ùå DO NOT:
1. Downgrade models to older versions (gpt-4o, claude-sonnet, gemini-1.5-pro)
2. Remove the settings button from UI
3. Change port back to 8888
4. Remove `.env` loading from web.py
5. Disable initial planner functionality
6. Set Gemini to `gemini-3-pro` instead of `gemini-3-pro-preview`

### ‚úÖ DO:
1. Always verify model versions match this file
2. Check that settings.json, .env, and settings.py are synced
3. Test that all providers initialize (check logs for "Failed to initialize")
4. Ensure deployment selection works (sends WebSocket message)
5. Keep API keys in .env, never hardcode

---

## üîç Validation Checklist

Before making changes to provider configuration:

- [ ] Check this file for correct model names
- [ ] Verify .env has correct GEMINI_MODEL (gemini-3-pro-preview)
- [ ] Verify .env has correct ANTHROPIC_MODEL (claude-opus-4.5-20251124)
- [ ] Verify .env has correct OPENAI_MODEL (gpt-5.1)
- [ ] Check settings.json matches .env values
- [ ] Check settings.py defaults match .env values
- [ ] Test that web server loads .env (check logs)
- [ ] Verify all 4 providers initialize successfully

---

## üìù Deployment Preferences

### Deployment Flow
1. Build mode completes ‚Üí Show deployment options
2. User selects deployment (or "Skip Deployment")
3. Frontend sends `deployment_selected` WebSocket message
4. Backend handles deployment and sends status messages
5. UI shows deployment progress and completion

### Required Event Handlers (app.js)
- `deployment_options` - Show deployment selector
- `deployment_started` - Show deployment initiation
- `status_message` - Display backend messages
- `deployment_completed` - Mark complete, re-enable send button

---

## üîß Quick Reference Commands

### Verify Configuration
```bash
# Check .env settings
grep -E "^(OPENAI|ANTHROPIC|GEMINI)_MODEL=" .env

# Check settings.json
cat ~/.aitril/settings.json | jq '.llm_providers | to_entries | .[] | select(.value.enabled == true) | {key: .key, model: .value.model}'

# Test provider initialization
python3 /tmp/test_provider_init.py
```

### Restart Web Server
```bash
# Kill existing server
pkill -f "uvicorn.*web:app"

# Start with .env loading and auto-reload
python3 -m uvicorn aitril.web:app --host 0.0.0.0 --port 37142 --reload
```

---

## üìö Model Version History

### Why These Specific Models?

**User explicitly requested these in conversation:**
- Web search confirmed GPT-5.1 released late 2025
- Web search confirmed Claude Opus 4.5 released Nov 24, 2025
- Web search confirmed Gemini 3 Pro released Nov 18, 2025

**Previous downgrades that were WRONG:**
- ‚ùå gemini-1.5-pro ‚Üí Should be gemini-3-pro-preview
- ‚ùå claude-sonnet-4-5-20250929 ‚Üí Should be claude-opus-4.5-20251124
- ‚ùå gpt-4o ‚Üí Should be gpt-5.1

---

## üé® UI Conventions

### Mode Names & Icons
- **Build** (üèóÔ∏è): Multi-phase with initial planner ‚Üí planning ‚Üí implementation ‚Üí deployment
- **Tri-lam** (üß¨): Parallel agents with optional initial planner
- **Consensus** (ü§ù): Agents debate to reach agreement
- **Ask** (üí¨): Single provider query

### Agent Display
- Planner agent: `üìã Planner (OpenAI)` with isPlanner flag
- Regular agents: Provider name with model badge
- Local models: Show "LOCAL" badge

---

## üíæ Backup Original Settings

If needed, restore from this checkpoint by:
1. Updating `~/.aitril/settings.json` with model values above
2. Updating `.env` with environment variables above
3. Updating `aitril/settings.py` defaults to match
4. Restarting web server to reload configuration

**Created**: 2025-11-28 by Claude Code
**Validated**: User confirmed all settings correct
